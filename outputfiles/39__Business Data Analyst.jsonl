{"text": "Name: elizabeth elizabeth"}
{"text": "E-Mail: elizabeth.elizabeth@gmail.com"}
{"text": "Address: Zhengzhou, China"}
{"text": "Github: https://github.com/elizabeth"}
{"text": "LinkedIn: https://linkedin.com/elizabeth"}
{"text": "Phone No. 470347332684"}
{"text": ""}
{"text": "Summary of Qualifications "}
{"text": "Over all 6+ years of Industry experience as a Business Analyst/Business Data Analyst with solid understanding of Business Requirements Gathering, Data warehousing, Data Modelling, Evaluating Data Sources, Translating Requirements into Specifications, Application Design."}
{"text": "Diverse experience in Banking, Financial Services, Mortgage."}
{"text": "Deep understanding of enterprise data warehouses."}
{"text": "Proficient in Technical and Business Writing, Business Process Flow, Business Process Modeling, Business Analysis and Testing various methodologies."}
{"text": "Expertise in Project Management i.e. Project Scoping, Planning, Estimating, Scheduling, Organizing, Directing, Controlling, Budgeting and Drafting Remedy Procedures."}
{"text": "Experience in facilitating Joint Requirement Planning (JRP) sessions with Business User Groups, conducting Joint Application Development (JAD) sessions with IT Groups and Conflict Management with Project team members."}
{"text": "Have considerable expertise in Metadata Management, Data Analysis, Data Profiling & Quality, Data Governance and Master Data management (MDM)."}
{"text": "Experience with IBM WebSphere Business Modeler to understand and transform business through superior business modeling."}
{"text": "In depth knowledge Rational Unified Process (RUP) methodology, Use Cases, Software Development Life Cycle (SDLC) processes, Agile, Object Oriented Analysis and Design (OOA/D)"}
{"text": "Worked with Rational Suite of tools to create requirements documents (Requisite Pro), visual data models (Rose), manage and track defects (Clear Quest)."}
{"text": "Competent in Creating Unified Modeling Language (UML) diagrams such as Use Case Diagrams, Activity Diagrams, Class Diagrams, navigational flows, story boards, UI specifications and Sequence Diagrams."}
{"text": "Proficient in the use of ORACLE (PL/SQL) SQL Loader, AB Initio ETL Design and programming, Shell Scripting, NCR TERADATA"}
{"text": "Extensive experience in conducting Market Research, Feasibility Studies, Data Analyses, Data Mapping, Data Profiling , Gap Analyses, Risk Identification, Risk Assessment, Risks Analyses, and Risk management."}
{"text": "Extensive experience in conducting Market Research, Feasibility Studies, Data Analyses, Data Mapping Gap Analyses, Risk Identification, Risk Assessment, Risks Analyses, and Risk management."}
{"text": "Knowledge with investment banking regulatory reporting regulations like Basel II Accord"}
{"text": "Experience with SOX, Regulatory Compliance and Controls. "}
{"text": "Worked on Launching the Master Data Management (MDM) initiative after gaining business buy-in, by defining and prioritizing Enterprise Master Data Entities based on industry criteria including their core attributes through the Data Governance Process."}
{"text": "Extensive experience in configuring data mapping between different Databases."}
{"text": "Extensive experience in developing Use Cases, creating Screen Mockups, conducting Gap Analysis and Impact Analysis, SWOT analysis, Cost Benefit Analysis, Risk Analysis."}
{"text": "Facilitated Change Management across entire process from Project conceptualization to Testing through Project Delivery, Software Development and Implementation Management in diverse Business and Technical Environments. "}
{"text": "Knowledge in the ETL (Extract, Transform and Load) of data into a data ware house/date mart and Business Intelligence (BI) tools like OBIEE Modules (Reporter, Supervisor, Designer, and Web Intelligence)."}
{"text": "Expertise in broad range of technologies, including business process tools such as Microsoft Project, Primavera, Promodel, MS Excel, MS Access, MS Visio, technical assessment tools, MicroStrategy Data Warehouse Data Modeling and Design."}
{"text": "Strong experience in conducting User Acceptance Testing (UAT) and documentation of Test Cases. Expertise in designing and developing Test Plans and Test Scripts."}
{"text": ""}
{"text": ""}
{"text": "Expertise:"}
{"text": ""}
{"text": ""}
{"text": ""}
{"text": ""}
{"text": "Professional Experience"}
{"text": "Bank OF America, Pennington, NJ                                                                                          Mar 2017- Feb 2019"}
{"text": "Sr. Business/ Data Analyst"}
{"text": "ASSET ALLOCATION/PORTFOLIO MANAGEMENT"}
{"text": "The project involved in the design and implementation of robust, fast and efficient front and back-end applications for a sophisticated Portfolio Management System in a fully automated electronic environment. This project implemented the APMS enabling the portfolio manager to manage, model and analyze the portfolio giving the maximum returns while taking minimum risk as per the need of their investors, which included two parts, first part was concerned with asset allocation and the second part towards rebalancing the risk."}
{"text": "Responsibilities"}
{"text": "Worked closely with Business users in defining the scope, analyzing business requirements and segregating them into high level and low level requirements\u00a0"}
{"text": "Formed a bridge between the Project Manager and the development team with effective presentations.\u00a0"}
{"text": "Documented and reported previous projects and follow ups for step-by-step project manuals."}
{"text": "Conducted JAD sessions with users across the globe to identify the requirements, use case analysis and outlining business rules.\u00a0"}
{"text": "Wrote advanced SQL queries to extract, manipulate, and/or calculate information to fulfill data and reporting requirements including identifying the tables and columns from which data is extracted. "}
{"text": "Responsible to test the functionality of Ab Initio graphs."}
{"text": "Worked as a Business Analyst/Data Analyst to translate customer product requirements into comprehensive, complete and accurate business requirements and functional specification."}
{"text": "Gathered requirements for creating the\u00a0rating\u00a0inputs screen for the policy system. "}
{"text": "Responsible for Data modeling and Mapping through data analysis to extract data elements from various OLTP\u2019s using ETL technique and utilized Business Intelligence Tool for report generation."}
{"text": "Used Data warehousing for Data Profiling to examine the data available (Data Analysis) in an existing database."}
{"text": "Modified the Ab Initio graphs to utilize data parallelism and thereby improve the overall performance to fine-tune the execution times."}
{"text": "Involved in MDM Process including data modeling, ETL process, and prepared data mapping documents based on graph requirements.\u00a0"}
{"text": "Documented all the issues regarding Data Integrity."}
{"text": "Used UML for Business Modeling for drawing the corresponding modeling diagram such as Use Case, Activity, Sequence, and Collaboration Diagrams."}
{"text": "Extract, synthesize and manipulate large\u00a0data\u00a0sets using Excel, Access, SQL, Visual Basic, and present them in\u00a0Cognos.\u00a0"}
{"text": "Analyzed, Revised and Created Test Plans according to business requirements."}
{"text": "Experience in Advanced modeling and calculations using Microsoft Power BI."}
{"text": "Worked with VBA Macros with Excel VBA, which automate tasks in Excel by writing macros."}
{"text": "Developed the VBA Integration with Excel feeds and SQL database, SQL Extraction, Transformations of Excel Data into SQL database."}
{"text": "Provided support to Data Architect and Data Modeler in Designing and Implementing Databases for MDM using ERWIN Data Modeler Tool and MS Access. "}
{"text": "Reviewed the data model and reporting requirements for Cognos Reports with the Data warehouse/ETL and Reporting team."}
{"text": "Tested the ETL AB Initio mappings and other ETL Processes (Data Warehouse Testing) "}
{"text": "Developed reports and dashboards using Microsoft Power BI stack - Power Pivot, power query."}
{"text": "Created Stored Procedures, User-Defined Functions, Ad-hoc Scripts and Cursors on Development and Test servers for pre-deployment testing. "}
{"text": "Performing Data Quality Checks and cleansing the incoming data feeds as and profiling the source systems data as per business rules."}
{"text": "Maintained and monitored project progress and status through MS Project."}
{"text": "Data visualization using Cognos."}
{"text": "Used SQL tools like TOAD to run SQL queries to view and validate the data loaded into the warehouse."}
{"text": "Did data profiling data mining, data mapping, data cleansing."}
{"text": "Worked closely with the Enterprise Data Warehouse team and Business Intelligence."}
{"text": "Performed extensive task which include Data Quality Analysis, Data lineage and Data Standardization data structures, data base design, data warehouses, business."}
{"text": "Improved performance of existing Ab Initio graphs."}
{"text": "Used intelligence/analytic tools, SQL, ETL tools, and data integration methods"}
{"text": "Used Cognos to perform regression analysis for managers to make prompt decisions with."}
{"text": "Using Microsoft Power BI and Power Query to extract data from external sources and modify data to certain format as required."}
{"text": "Developed\u00a0SAS macros\u00a0for Data cleaning, Data mining and Reporting."}
{"text": "Data mapping, logical data modeling, used SQL queries to filter data within the Oracle."}
{"text": ""}
{"text": ""}
{"text": "Capital One, Richmond, VA  \t\t                                                                           Jan 2015 - Feb 2017         Business Analyst/Data Analyst"}
{"text": "Capital one uses risk to net interest income as the metric for market risk economic capital. An additional contribution to our income volatility from market risk arises from situations where some or all of a positions change in market value must be included in income. This includes all derivatives that for which hedge accounting is not used, ineffectiveness in hedge accounting relationships, mortgage servicing rights fair value (MSR), the mortgage origination pipeline, our Bank Owned Life Insurance (BOLI) portfolio, and certain stock and option positions in Share Builder. Data was spread out in multiple and diverse sources in databases located in different regions. The requirement demanded an integrated, unified data pool that was truly subject-oriented, time-variant and nonvolatile. "}
{"text": "Responsibilities"}
{"text": "Interviewed Business Users to gather Requirements and analyzed the feasibility of their needs by coordinating with the project manager and technical lead."}
{"text": "Collects requirements from department managers and users for enhancements. Acts as liaison between clients and development. Facilitates sessions to bring business requirements and functionality into SAP system development and enhancement."}
{"text": "Prepared Business Requirement Documents (BRD\u2019s) after the collection of Functional Requirements from System Users that provided appropriate scope of work for technical team to develop prototype and overall system."}
{"text": "Designed ETL jobs for extracting data from heterogeneous source systems, transform and finally load into the Data Marts."}
{"text": "Used Ab Initio graphs to load data into the Teradata database."}
{"text": "Collaborated with Basel II team on credit risk analysis and issue resolution."}
{"text": "Communicated the implementation of the new calculation framework of Risk Weight Asset under Basel II"}
{"text": "Worked in the ETL Procedures and processes. "}
{"text": "Followed Agile/Scrum methodology for the life cycle of the project. "}
{"text": "Used Ab Initio graphs to load data into the DB2 and Teradata database."}
{"text": "Developed user stories and attended stand up meetings on a daily basis."}
{"text": "Prepared for GAP Analysis; identified and documented improved areas to meet capital requirement regulations for Basel II Compliance."}
{"text": "Enhancing supporting documentation (policies, frameworks, standards, methodologies, and modeling documents) to demonstrate compliance with the Basel II Accord."}
{"text": "Identified/documented data sources and transformation rules required to populate and maintain data warehouse content. "}
{"text": "Developed parameter sets for the Ab Initio graphs to run a graph with different inputs."}
{"text": "Was responsible for indexing of the tables in that data warehouse."}
{"text": "Reverse Engineered the existing ODS in to Erwin."}
{"text": "Develop Logical and Physical data models that capture current state/future state data elements and data flows using Erwin. "}
{"text": "Worked on data modeling and produced data mapping and data definition documentation"}
{"text": "Configured the Data mapping between Oracle and SQL Server."}
{"text": "Tested Performance & Accuracy related queries under SQL Server"}
{"text": "Designed and implemented basic SQL queries for testing and report/data validation"}
{"text": "Manage Scope and change throughout the SDLC process of the product."}
{"text": "Created Use cases, activity report, logical components and deployment views to extract business process flows and workflows involved in the project. Carried out defect tracking using Clear Quest"}
{"text": "Designed, developed and Unit tested Ab Initio graphs using GDE for Extraction, Transformation and Loading of data from source to target"}
{"text": "Managed backlogs within the agile projects."}
{"text": "Used Data warehousing for Data Profiling to examine the data available in an existing database."}
{"text": "Created custom reports in Payables in Cognos according to user requirement"}
{"text": "Prepared graphical depictions of Use Cases, Use Case Diagrams, State Diagrams, Activity Diagrams, Sequence Diagrams, Component Based Diagrams, and Collateral Diagrams and creation of technical design (UI screen) using Microsoft Visio."}
{"text": "Worked on Documentum for Version Controlling, to maintain up to date changes in the Documents."}
{"text": "Assisted to develop the Test Plan, Test Cases and Test Scenarios to be used in testing based on Business Requirements, technical specifications and/or product knowledge."}
{"text": "Conducted User Acceptance Testing, gathered and documented User Manuals and Business Rules"}
{"text": ""}
{"text": ""}
{"text": "Alliance Bank, Chicago, IL \t\t\t\t                                                Nov 2012 - Dec 2014"}
{"text": "Business Analyst/Data Analyst \t\t\t\t\t                                      "}
{"text": "Alliance Bank, one of the largest bankcard providers in the nation, offers broad range of lending, deposit and membership based products. Alliance Bank offers online services such as 24hour online account access to credit card accounts, instant online account opening for deposit accounts, instant decisions for Aria visa, Alliance (Visa and Master) credit cards and loan comparisons through GetSmart.com"}
{"text": "Project OLA (On Line Access): 24-hour online access to Aria and Alliance Bank credit cards; the customers can login and view their account information online. They can make online payments, change their contact information and contact customer service representatives for questions"}
{"text": ""}
{"text": "Responsibilities:"}
{"text": "Analyzed business requirements, system requirements, data mapping, requirement specifications, and responsible for documenting functional requirements and supplementary requirements in Quality Center 9.2"}
{"text": "Tested ETL jobs as per business rules using ETL design document"}
{"text": "Assisted in creating fact and dimension table implementation in Star Schema model based on requirements."}
{"text": "Involved in the testing of Data Mart built by using Informatica Power Center Designer."}
{"text": "Extensively used Informatica Power Center for Extraction, Transformation and Loading process."}
{"text": "Extensively tested several ETL Mappings developed using Informatica."}
{"text": "Tested Teradata load utilities Fast load, Multiload and FastExport to extract, transform and load the Teradata data warehouse."}
{"text": "Effectively distributed responsibilities, arranged meetings and communicated with team members in all phases of the project. "}
{"text": "Used import and export facilities of the application to download/upload XMLs of failed test cases so as to re-verify."}
{"text": "Writing UNIX scripts to perform certain tasks and assisting developers with problems and SQL optimization."}
{"text": "Extensively used Autosys for automation of scheduling jobs on daily, bi-weekly, weekly monthly basis with proper dependencies."}
{"text": "Wrote complex SQL queries using joins, sub queries and correlated sub queries"}
{"text": "Performed Unit testing and System Integration testing by developing and documenting test cases in Quality Center."}
{"text": "Designed and developed UNIX shell scripts as part of the ETL process, automate the process of loading, pulling the data."}
{"text": "Tested ad hoc and canned reports for Business objects."}
{"text": "Responsible for migrating the code changes from development environment to SIT, UAT and Production environments."}
{"text": "\n"}
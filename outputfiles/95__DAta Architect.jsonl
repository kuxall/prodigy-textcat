{"text": "Name: frances frances"}
{"text": "E-Mail: frances.frances@gmail.com"}
{"text": "Address: Maoming, China"}
{"text": "Github: https://github.com/frances"}
{"text": "LinkedIn: https://linkedin.com/frances"}
{"text": "Phone No. 329548047573"}
{"text": "Modeling, designing and implementing OLTP, OLAP databases and data warehousing solutions"}
{"text": "Technically sophisticated, I have good knowledge on Process Group and Knowledge area of Business Analyst / Data Analyst / Data modeler/ Cloud Developer and Data Architect,offering 15 plus years of experience translating the needs of non-technical clients into data storage.  I\u2019m Strong interpersonal skills, highly adaptive at diplomatically facilitating, discussions and negotiations with stakeholders.  I\u2019m Skilled in the Initiating, Planning, Executing, Monitoring, Controlling and Closing of the project. I\u2019m skilled in themining and analysis solutions that accommodate long-lasting capacity and scalability for a solid business future. "}
{"text": ""}
{"text": "PROFESSIONAL SUMMARY"}
{"text": ""}
{"text": "14+ years of experience in IT industry with 12 + years of specialized practical experience in clarifying business requirements through Business Analysis, Data Modeling, Dimensional Modeling, Data Analytics, Data Quality, Design process and system improvements to increase productivity and reduce costs."}
{"text": "Excellent Analytical skills to understand the Business Process and Functionality. Developing Functional Specifications for business process refinement and automation,Data Modeling, system architecture, and conducting feasibility studies."}
{"text": "Proven experience in relational and dimensional data modeling, data management, data warehousing, data transformation, metadata and master data (reference data) management and business intelligence tools."}
{"text": "Knowledge of Advance SQL keywords and concepts."}
{"text": "12+ years of Dimensional Data Modeling experience using Data modeling, Relational Data modeling, ER/Studio, Erwin, Sybase Power Designer, Star Join Schema/Snowflake modeling, FACT & Dimensions tables, Conceptual, Physical & logical data modeling."}
{"text": "Experience incomputing platforms that allow analytics  to combine structured, complex data and build processing and analytical applications across data sources and types;"}
{"text": "Advanced information management and new data processing techniques may be applied to extract the value locked up in this data called Hadoop (HDFS) along with processing large data sets in parallel across a Hadoop cluster and the utilization of Hadoop MapReduce framework."}
{"text": "Additionally experienced in NameNode where Hadoop stores all the file location information in HDFS andtracks the file data across the cluster or multiple machines."}
{"text": "Predicting market trends or identifying market shifts or in other words, allowing the businesses to look through the windshield for what is coming."}
{"text": "Some know of SITE CATALYST TAGGING. For example s.props, s_eVars or s.events. Initiates and builds an image request for a 1x1 pixel image, also called a web beacon that concatenates a query string of name/value pairs of analytics data to send to the Adobe Data Collection Layer."}
{"text": "Knowledge of JIRA which is a workflow management system tool that lets track work in any scenario."}
{"text": "Highly skilled in the usage of ETL tools for DataStage (Talend, Informatica, SSIS, SSRS) developing features of Teradata PDE, Amp, Bynet, PE, vDisk and Virtual storage system (VSS).  Knowledge of MultiLoad, TPUMP and BTEQ utilitywhich is a general-purpose, command-based toolfor Teradata. "}
{"text": "Work on Background process in oracle Architecture. Also drill down to the lowest levels of systems design and construction."}
{"text": "As a ArchitectUML models and leverage the advanced executable code generators to target different domains."}
{"text": "Determine the physical architecture of oracle ( Datafiles\u201d*.dbf\u201d, Controlfiles \u201c *.ctl\u201d) est."}
{"text": "Experienced in Businesses Analytics, to provide comprehensive predictive analytic, financial performance and strategy management, to improve business performance and predict future outcomes."}
{"text": "Experience in conducting Joint Application Development (JAD) sessions with SMEs, Stakeholders and other project team members for requirement gathering and analysis."}
{"text": "Responsible for interacting with business partners to identify information needs and business requirements for reports."}
{"text": "Strongly capable of handling VLRDB (Very Large Relational Data Bases) of about 5TB with expert level working knowledge of the architecture involved."}
{"text": "Experience in back-end programming including schema and table design, stored procedures, Triggers, Views and Indexes."}
{"text": "Expertise in Normalization/Demoralization techniques for optimum performance in relational and dimensional database environments."}
{"text": "Highly proficient in Data Modeling retaining concepts of RDBMS, Semantic (SDM),Logical and Physical Data Modeling until 3NormalForm (3NF) and Multidimensional Data Modeling Schema (Star schema, Snow-Flake Modeling, Facts and dimensions). Complete knowledge of data warehouse methodologies (Ralph Kimball, Inmon), ODS, EDW and Metadata repository."}
{"text": "Knowledge of DBA performs all activities related to maintain a successful database environment. I always keep myself abreast of emerging technologies and new design approaches i.e. designing, implementing the database system."}
{"text": "Expert in the Data Analysis, Design, Development, Implementation and Testing using Data Conversions, Extraction, Transformation and Loading (ETL) and SQL Server, ORACLE and other relational and non-relational databases."}
{"text": "Experience in leading the offshore team, supporting team effort through sharing of technical knowledge to turnaround deliverables to meet aggressive deadlines."}
{"text": "Managed Full SDLCprocesses involving requirements management, Workflow analysis, source data analysis, data mapping, metadata management, data quality, testing strategy and maintenance of the model."}
{"text": "Consolidate and audit metadata from disparate tools and sources, including business intelligence (BI), extract, transform, and load (ETL), relational databases, modeling tools, and third-party metadata into a single repository."}
{"text": "Expert level understanding of using IBM Cognos SPSS, Cognos TM1 and Business Analytics family software."}
{"text": "Expert level understanding of using different databases in combinations for Data extraction and loading, joining data extracted from different databases and loading to a specific database."}
{"text": "Excellent understanding of an Approach to MDM to creating a data dictionary, Using Informatica or other tools to do mapping from sources to the Target MDM Data Model."}
{"text": "Excellent understanding of Hub Architecture Style for MDM hubs the registry, repository and hybrid approach."}
{"text": "Excellent understanding and working experience of industry standard methodologies like System Development Life Cycle (SDLC), as per Rational Unified Process (RUP), AGILE and Waterfall Methodologies."}
{"text": "Excellent knowledge in the ETL (Extract, Transform and Load) of data into a data warehouse/DateMart and Business Intelligence (BI) tools like Business Objects Modules (Reporter, Supervisor, Designer, and Web Intelligence)."}
{"text": "Well versed with client server environment and tools like SQL*Loader, UNIX shell scripts and TOAD."}
{"text": "Used NetCDF Java library is an implementation of the CDM which can read many file formats besides NetCDF"}
{"text": "Common Data Model (CDM) for the scientific Datasets which merges the NetCDF, OPeNDAP, and HDF5 data models"}
{"text": "Excellent team member with interpersonal and communication skills and trouble-shooting capabilities, highly motivated, result oriented with strong analytical, organizational, presentation and problem solving skills."}
{"text": "Expert in developing effective working relationships with client team to understand support requirements, develop tactical and strategic plans to implement technology solutions, and effectively manage client expectations."}
{"text": "Excellent knowledge for creating Databases, Tables, Cluster/Non-Cluster Index, Unique/Check Constraints Views, Stored Procedures, Triggers, Rules."}
{"text": "Have training in AWS cloud databases (Amazon RDS) and using Amazon virtual private cloud (VPC) which supported two EC2 platforms (VPC and Classic). Create new option group and assign it to the DB instance such as Oracle TDE. Create Amazon RDS MySQL DB instance such as MySQL versions, storage engine security.  "}
{"text": "Build, format, and customize Oracle Business Intelligence (BI) analyses, and how to create and update dashboards in Oracle BI EE 12c "}
{"text": "Using Erwin to connective to the SQL Server database and read & write Model Mart Database.In Erwin migrates the model from the Erwin Model Manager R8.x to New Erwin Model Mart R9.x (Each model is upgraded during the migration to new Model Mart)"}
{"text": "Using a text editor such as Notepad to open the MVS file."}
{"text": "Managing on shore and offshore team.   "}
{"text": ""}
{"text": "TECHNICAL SKILL SET"}
{"text": ""}
{"text": ""}
{"text": "EXPERIENCE:  "}
{"text": "CVS RxConnet,  Woonsocket RI.                                                                                               April 2016- Present"}
{"text": "Data Architect/ Data Analysis "}
{"text": "The purpose of the Project Charter is to document the reasons for undertaking the Enhanced Pharmacy Credentials project, and assumption, constraints, scope, deliverables, project approach estimated effort, and key stakeholders."}
{"text": "The purpose of the Enhanced Pharmacy Credentials Evaluate and Analyze the impact of new or enhanced requirements in RxConnect Architecture project is to address the needs to restrict or allow both pharmacist and technicians to complete function within RxConnect based upon. Assessment involves impact analysis to Architectures domains as per the defined NFRs."}
{"text": "Use QlikView for development life cycle, Requirement gathering, Discussion, understand data, visualization, Analyze data sources and the relationships among the data elements. "}
{"text": "Information Architecture:"}
{"text": "Application Architecture"}
{"text": "System Data Architecture"}
{"text": ""}
{"text": "Data Model for relational database:"}
{"text": "Create data model"}
{"text": "Create data load "}
{"text": "Technical Architecture:"}
{"text": "ReConnect Frameworks"}
{"text": "Infrastructure Architecture"}
{"text": "Deployment Architecture"}
{"text": "Security Architecture"}
{"text": "Key Achievements:"}
{"text": "Also designa process for Problematic for SQL for Prod and AWR reportas a Data Architect work on AWR andNew Defects, identifies the priority. Share SQL_ID from AWR with Prod Architect to determine if there are pre-existing defects. Once the defect fixed and promoted in production."}
{"text": "Tool; Oracle11g, 12c, Oracle SQL Developer, Oracle client 11.2, Oracle Web logic 12.1.2   SharePoint,PL/SQL, SQL Server 2008, and 2008 R2 Excel, OBIEE, MS 0ffice 2007, QlikView, Visio 2010. Citrix web Interface, Java Developer, Eclipse Java EE 4.4, File Zilla 3.3, CA Clarity PMP, Open logic Tortoise 1.9.2, Putty."}
{"text": "Capital One Bank, West Creek Richmond, VA                                                                   Oct 2015 to  Dec 2015"}
{"text": "Technical Business Analysis / Data Architect"}
{"text": ""}
{"text": "Analyze and improve businesses."}
{"text": "Find solutions to problems."}
{"text": "Build things based on the requirements."}
{"text": "Identify Risks and register."}
{"text": "Perform qualitative Risk Analysis."}
{"text": "Give description of the overall approach to risk on the project."}
{"text": ""}
{"text": "To defined as the discipline of\u00a0recognizing business needs and determining solutions to certain business problems and Analysis of business requirements to function as usual and to improve how they function. Solutions include a systems development component. So it can also comprise of organizational change, process improvement or strategic planning and policy development collection of tools, techniques and skills which aid the investigation of past business performance also helps gain insights of future performance. Generally, focus mostly on data and statistical analyses.Aim of project to embed high quality data management capabilities across enterprise data, EDM and Digital Analytics are excited to announce the Digital Data Quality and Governance proof-of-concept initiative. The proof-of-concept will help to mature capabilities in managing and governing digital data in a federated development and consumer landscape. Use QlikView for comparative analysis and use to set Analysis and Alternate state."}
{"text": "Key Achievements "}
{"text": "SDLC type methodologies for Business Analysis projects"}
{"text": "Functions and processes."}
{"text": "Enterprise architecture"}
{"text": "Process architecture"}
{"text": "Technology architecture"}
{"text": "Organization architecture"}
{"text": "Tool: Adobe SiteCatalyst ,Oracle11g, 12b, 13g, Erwin 9.6.01,7.5.2,QlikView, NoSQL, Hadoop, IBM Cognos,Tableau, SharePoint, SSIS, SSAS, SSRS XML, PL/SQL, SQL Server 2005, 2008, and 2008 R2 Excel, OBIEE, Access, Visio."}
{"text": ""}
{"text": "Highmark Inc, Pittsburgh, PA                                                                                               May 2015 to July 2015"}
{"text": "Role: Information Architecture & Modeling"}
{"text": "Highmarkis a not-for-profit health carecompany based in Pittsburgh, Pennsylvania, United States. It is the largest health insurer in Pennsylvania, and through a purchase in 1996, the largest health insurer in West Virginia and also later Delaware. As Highmark Blue Cross Blue Shield, it primarily serves the 29 counties of western Pennsylvania. As Highmark Blue Shield it services 21 counties of Central Pennsylvania and the Lehigh Valley. There is also a presence in the border areas of eastern Ohio, and all of West Virginia through its subsidiary Highmark Blue Cross Blue Shield West Virginia. Highmark has a stake in the largest health insurer in northeastern Pennsylvania as well, Blue Cross of North East Pennsylvania BCNEPA. It is currently[timeframe] one of the largest not-for-profit health insurers in the United States which owns several for-profit subsidiaries. "}
{"text": "Key Achievements                              "}
{"text": "Work with EDW Modeling team: Teradata DBAs"}
{"text": "With EDW team share Model on SheriPint"}
{"text": "Create Dimensional Model"}
{"text": "Create Erwin subject area for the changes."}
{"text": "Name subject are "}
{"text": "DB work item Quote"}
{"text": "Update Service Manager phase to In work"}
{"text": "Completing model changes, Save reports"}
{"text": "New Model Mart creates."}
{"text": "Upgrade During the migration to the new Model Mart. "}
{"text": "Create a Physical Data Model report named: DB work item PDM.pdf"}
{"text": "Create a Data Dictionary report named: DB work item DD.pdf "}
{"text": "Send notification that model change is ready for review"}
{"text": "Turn over model to DBAs upon customer approval"}
{"text": "Save model on LAN in ToDBA folder"}
{"text": "Update Service Manger phase: DBA Analysis"}
{"text": "Save reports to Published folder"}
{"text": "Email to requester and  CC Team "}
{"text": "Created table for Oracle 13.1 and DB2 8.1  "}
{"text": "Create Entity-Relational Model"}
{"text": "Modify and add Column in Model"}
{"text": ""}
{"text": "Environment:  Oracle, 8 and 11g, DB2, Mainframe, Teradata, QlikView, Erwin 8.0 and 9.3, SharePoint , SSIS, SSAS, SSRS XML, PL/SQL, SQL Server 2005, 2008, 2008 R2 and 2012 R2, Excel, Access, Visio."}
{"text": ""}
{"text": ""}
{"text": ""}
{"text": "Waddell & Reed, Shawnee Mission, KS                                                                           April 2015 to May 2015"}
{"text": "Role:     Data Analyst "}
{"text": "Waddell & Reed asset management and financial planning company provide customized financial planning and investment services to clients throughout the United States.  It operates asset management and distribution subsidiaries, including Ivy Investment Management Company and Waddell & Reed Investment Management Company."}
{"text": "The project name is IDQ EST Business Information."}
{"text": "The project scope is move the Legacy Data from mainframe, source system (CERD, IIR) to SQL Server is Target changing to MDMusing Informatica Data Quality empowers to managing data quality across the enterprise.Use Informatica Hot Fix to discover and define business logics and collaborate on business project. To delivers authoritative and trustworthy data to all stakeholders, projects, and business applications\u2014on premise or in the cloud."}
{"text": "Key Achievements"}
{"text": "Proactively monitor and cleanse data across the enterprise"}
{"text": "Review approach definition and identify potential solutions"}
{"text": "Ensure quality standards, criteria and targets are documented in the quality plain"}
{"text": "Remove process and role ambit  "}
{"text": "Script table as inset to new Query edit "}
{"text": "Enable business and IT collaboration in the governance of data"}
{"text": "MSD SDLC Phase"}
{"text": "Achieve better business outcomes and maximize your return on data"}
{"text": "Repository / Domain Details"}
{"text": "Connect IDQ Developer environment"}
{"text": "Stage environment to migration and test"}
{"text": "Work on subject Area"}
{"text": "LDG Data Review"}
{"text": "Spec Assigned"}
{"text": "MDM Reviewed"}
{"text": "Source to Target Matrix"}
{"text": ""}
{"text": "Environment:  Oracle12g, IBM Cognos TM1, Erwin 8.0, NoSQL, Hadoop, IBM Cognos, Talend, QlikView , SSIS, SSAS, SSRS XML, PL/SQL, SQL Server 2005, 2008, 2008 R2, 2012 R2 Excel, Access, Visio."}
{"text": ""}
{"text": ""}
{"text": ""}
{"text": "Cogent Data Solutions, Hoffman Estate, IL                                                                    April 2014 to April 2015"}
{"text": "Role:      Senior Data Modeler / Data Architect"}
{"text": "The Developed data models for Cook county, IL government. Thedata model contained data elements of patients and are used to give those patients Preventive health-care. Some elements that are contained in these data models are: find best GP (primary care physician), Hospital, Emergency room (ER), test centers for diagnostics, drugs etc. The scope of the project is to bring down cost of health-care from $850 per person to $90 to $150 per person. We UsedMapReduce and a distributed processing system to file and store data. The project was to design and develop Data Marts from Oracle Data Warehouse, to migrate the data from different (Teradata) sources into the databases using SSIS in generating customer profile reports, customer transaction reports, compliance reports, Audit reports using SSRS. Team used the data governor to data quality monitoring against production data in the goldensource to communicate errors in data entry back to the operations team members or to technology for corrective action. I was Involved in all the steps and scope of the project reference data approach to MDM, Creating a Data Dictionary and Mapping from Sources to the Target in MDM Data Model. Also try to use Semantic models enable users to ask questions of the information in a natural way and help to identify patterns and trends in this information and discover relationships between disparate pieces of information."}
{"text": "Model/Ontology Management \u2013 Which can enables users to build ontologies or to import them.\u00a0The knowledge model provides a layer of abstraction required for users to interact with the information in a natural way. The model is populated with known concepts, facts and relationships and reveals what data means and where it fits in the model."}
{"text": "Lineage \u2013 The knowledge model tracks and records the history or \u201clineage\u201d of the information, which is important in many analytical applications. Moreover, changes in the model are tracked to enable understanding of changes over time. This\u00a0helps answer questions such as \u201cwhen did we learn this?\u201d and \u201cwhy was this decision made?\u201d"}
{"text": "Workflow \u2013 The Thetus workflow engine enables the integration of various analytics including entity extraction, link analysis and geotagging. Workflow is automated based on rules and conditions defined in the model."}
{"text": ""}
{"text": "Used Talend Open Studio for ETL design and Data Integration make the development process simpler and faster.Birst\u2019suser-ready data to designed and optimized for ROLAP-style analytics, Kimball style star-schema with a multi-dimensional view of all data. Used Birst's user-ready data store supports Type SCD1 and SCD2 dimensions, and manages snapshots automatically. Data loading and updates are done through incremental process with built in Birst change detection. I did using Birst\u2019s unified business model to join data from Birst\u2019s user-ready data store with data in real-time from another source, cloud or on-premises. Birst Used in to combines ad hoc analysis of data and banded report into a single user interface report or visualizationwriting. Accessed on Mobile devices via HTML5 or Birst\u2019sNative iPad application or scheduled for delivery by email, Birst business intelligence platform exposed that into dashboard, "}
{"text": "Use CDM which contain elements that define PHI under HIPAA, including encounter dates and date of birth. Use Distributed analytic programs the date fields for analysis, person-level analysis under an IRB, with all necessary data agreements in place and necessary \u201ccross-walks\u201d between the arbitrary identifiers included in the CDM and their originating data are not specified in the scope of the CDM.  To maintained each data partner. Locally maintained \u201cmapping tables\u201d are tables necessary to implement so that each data partner has the ability to map arbitrary identifiers back to the originating data and patient. Use Mapping tables for implementation of the CDM v1.0. Designed the table identify periods during which a person is expected to have complete care so capture that data. Members with medical coverage, drug coverage, or both should be included. A record is expected to represent a unique combination of PATID, ENR_START_DATE, and BASIS. A break in enrollment (of at least one day) or a change in the chart abstraction flag should generate a new record. That ENROLLMENT table provides an important analytic basis for identifying periods during which medical care should be observed, for calculating person-time, and for inferring the meaning of unobserved care. "}
{"text": "Key Achievements"}
{"text": "Planning meeting and Analysis."}
{"text": "The requirements documentation and the project scope statement."}
{"text": "Validate scope."}
{"text": "Perform quantitative risk Analysis."}
{"text": "Perform administrative tasks, including creation of database objects such as database, tables, and views, using SQL DCL, DDL, and DML requests."}
{"text": "Focus on integration overlap and Informatica\u2019s newer commitment to MDM with the acquisition of Identity Systems."}
{"text": "Review the change to understand how it affects scope, cost, time, quality, risk and costumers satisfaction."}
{"text": "Observe and solve the issue of MDM."}
{"text": "AsArchitect implement MDM hub to provide clean, consistent data for a SOA implementation."}
{"text": "Using Erwin to customize report display and export reports to HTML."}
{"text": "With Erwin Tools generate graphical diagrams that drill-into to view detailed metadata."}
{"text": "In Erwin DM creating Logical and Physical Model."}
{"text": "Used BTEQ script to create a sample tables. Redefine the partitioning of a populated table."}
{"text": "Use RDBMSs to implement simple CRUD (Create, Read, Update, and Delete) functionality."}
{"text": "In Teradata use cursor logic to generate a sequence of dynamic SQL statements."}
{"text": "Developed complex mapping to extract data from diverse sources including flat files, RDBMS tables, legacy system files, XML files, Applications and Teradata. "}
{"text": "UseBirst\u2019sready data store sits on top of all data and combines different sources of corporate data. Optimized ROLAP-style analytics, providing a Kimball style star-schema with a multi-dimensional view of all data. "}
{"text": "Involved in gathering user requirements and specifications."}
{"text": "Involved in stored procedures, functions, and database triggers and maintained referential integrity and implemented complex business logic."}
{"text": "Created Dimension types such as Standard dimension, Parent-Child dimension and Role Play dimension in SSAS."}
{"text": "Designed and created views for security purposes. Implemented rules, defaults, and user-defined data types. Tested queries to optimize procedures and triggers to be used in production."}
{"text": "Developed SSIS Templates which can be used to develop SSIS Packages such a way that they can be dynamically deployed into Development, Test and Production Environments."}
{"text": "Created SSIS packages for different data loading operations for many applications."}
{"text": "Performed Data modeling for existing Databases using Toad Data Modeler and ER Studio."}
{"text": "Designed VB forms using the forms and crystal reports were made for business reporting purpose."}
{"text": ""}
{"text": "Environment:  Oracle 11g, OBIEE,  IBM infoSphere, IBM Cognos, IBM Cognos TM1, Erwin r9.5,ER/Studio 9.7, IBM InfoSphere Data , HP Hadoop, Data Stage,QlikView, Windows 7 XML, Excel, Access, Visio, SSIS , SSRS, MySQL, RazorSQL, SQL Server 2005, 2008, 2008 R2 and 2012 , EMC PX12-450R Network Storage Array."}
{"text": ""}
{"text": "Volkswagen Group of America, Auburn Hills, MI                                                   March 2010 to March 2014"}
{"text": "Role:     Business Analyst / Senior Data Modeler"}
{"text": "Re-factored the data sources and performed work based on requirement priority. Model storm data throughout the project\u2019s complete Software Development Life Cycle (SDLC) using JIT. Managed requirements, having single definition for a data element or business term, Allowing business leaders to better understand their clients\u2019 needs and wants and data analysis, domain knowledge, collection of information organized into interrelated objects like table spaces, tables, and indexes. I performed theData Profiling, designing the blueprint for improved data quality. Also perform the data modeling, system analysis, architecture and design, development, testing and deployment of business applications. Used to processes such as Disciplined Agile Delivery (DAD) and Unified Process. Extract, Transform, Load transactions (ETL) using Database. UsedAgile approach to Master Data Management (MDM). Also was directly involved with the actual modeling effort itself. Attended the JAD sessions for Business requirements gathering and represented in a logical data model, creating data mapping documents, writing functional specifications and queries. I Created the Erwin reports in HTML, RTF format depending upon the requirement. Published data model in Model Mart, created naming convention files. I Co-coordinated with DBA's to apply the data model changes, including requirement analysis, design and implementation.Use Informatica PowerCenter to move data MDM into the hubs. I flow the data governor, data quality monitoring against production data in the goldensource to communicate errors in data entry back to the operations team members or to technology for corrective action.   "}
{"text": "Key Achievements"}
{"text": "Created complex Stored Procedures for data retrieval."}
{"text": "Created SSIS Packages using Pivot Transformation, Execute SQL Task, Data Flow Task, etc to import data into the data warehouse."}
{"text": "Created user defined functions in SSRS using VB script."}
{"text": "Responsible for creating OLAP cubes for deep through analysis using SSAS 2008."}
{"text": "Use the power of Birst\u2019s unified business model to join data from Birst\u2019s user-ready data store with data queried in real-time from another source, cloud or on-premises. "}
{"text": "Used data profiling tool for automates the discovery process."}
{"text": "Used data profiling automation to uncover the characteristics of the data and the relationships between data sources before any data-driven."}
{"text": "Developed strategies for data warehouse implementations, data acquisitions, provided technical and strategic advice and guidance to senior managers and technical resources in the creation and implementation for data architecture and data modeling"}
{"text": "Perform administrative tasks, including creation of database objects such as database, tables, and views, using SQL DCL, DDL, and DML requests."}
{"text": "Use Sybase PowerDesiner support several types of model."}
{"text": "Integrated crystal reports using Erwin Data Modeler."}
{"text": " Us Erwin to support for Teradata 13.0 and SSL."}
{"text": "Set in Erwin Diagram Parent to Child identifying relationships. "}
{"text": "Transformation and reverse engineering using Erwin tool. "}
{"text": "In Erwin DM creating Logical and Physical Model."}
{"text": "Used BTEQ script to create a sample tables. Redefine the partitioning of a populated table."}
{"text": "Using cursor logic to generate a sequence of dynamic SQL statements in Teradata."}
{"text": " Use RDBMSs to implement simple CRUD (Create, Read, Update, and Delete) functionality."}
{"text": "Developing complex mappings to extract data from diverse sources including flat files, RDBMS tables, legacy system files, XML files, Applications and Teradata. "}
{"text": "Defined corporate Metadata definitions for the enterprise data supported databases including operational source systems, data stores and data marts developed logical and physical data models and documented source data from multiple sources, internal systems, external source systems, and third party data."}
{"text": "Used various Transformations in SSIS Dataflow, Control Flow using for loop Containers, and Fuzzy Lookups. Created several Staging Databases. Used SSIS and T-SQL stored procedures to transfer data from OLTP databases to staging area and finally transfer into data marts and performed action in XML"}
{"text": "Environment:  Oracle11g,OBIEE,  IBM Cognos TM1, Erwin 7.5.2, NoSQL, Hadoop,QlikView, IBM Cognos, Talend, SSIS, SSAS, SSRS XML, PL/SQL, SQL Server 2005, 2008, and 2008 R2 Excel, Access, Visio, Windows XP."}
{"text": ""}
{"text": "Client:  Chartis International, Parsippany, NJ                                                                    Aug 2009 to Feb 2010  "}
{"text": "Role:     Data modeler / Business Data Analyst"}
{"text": "Attend the JAD sessions for requirements gathering, creating data mapping documents, writing functional specifications, queries. Created Erwinreports in HTML, RTF format depending upon the requirement, Allowing business leaders to better understand their clients\u2019 needs and wants. Published Data model in model mart, created naming convention files, co-coordinated with DBAs\u2019 to apply the data model changes, Including requirement analysis, design and implementation. Used MDM to maintain data quality initiatives and ensure integration with organization\u2019s current standards (i.e. Informatica, or Trillium) that Siperian organization's find full data management solution in it. Check the MDM Data Model can provide data for performance reports.TeamUse the data governor to data quality monitoring against production data in the goldensource to communicate errors in data entry back to the operations team members or to technology for corrective action."}
{"text": "Description:"}
{"text": "Chartis (Chartis, Inc.), is a division of AIG in the process of being spun off, formerly referred to as the 'Property Casualty Insurance' part of AIG.American International Group, Inc. (AIG) is a leading international insurance organization serving customers in more than 130 countries. AIG companies serve commercial, institutional and individual customers through one of the most extensive worldwide property casualty networks of any insurer. In addition, AIG companies are leading providers of life insurance and retirement services in the United States."}
{"text": "Key Achievements"}
{"text": "Responsible for creating Databases, Tables, Cluster/Non-Cluster Index, Unique/Check Constraints Views, Stored Procedures, Triggers, Rules."}
{"text": "In Erwin DM creating Logical and Physical Model."}
{"text": "Creating a User-defined Function, To Verify a Date. "}
{"text": "Perform administrative tasks, including creation of database objects such as database, tables, and views, using SQL DCL, DDL, and DML requests."}
{"text": "Used BTEQ script to create a sample tables. Redefine the partitioning of a populated table."}
{"text": "Ensure compliance of Data Quality in MDM."}
{"text": "Determine the Target in MDM."}
{"text": "Specify the Mapping between Sources and Target in MDM."}
{"text": "Developed SSIS Packages to Consolidate date from various data Sources and also Data loads from various types of sources files (EXCEL, Access, Flat files, CSVs) and converted XL to SQL reporting."}
{"text": "Designed and developed complex mappings to extract data from diverse sources including flat files, RDBMS tables, legacy system files."}
{"text": "Use RDBMSs to implement simple CRUD (Create, Read, Update, and Delete) functionality."}
{"text": "Involved in daily loads (FULL & INCREMENTAL) into Staging and ODS areas, troubleshooting process issues and errors."}
{"text": "Creating a Stored Procedure to Update Accrued Interest."}
{"text": "Environment:  Oracle 10g, OBIEE, Data Stage, Erwin 7.5.2, HP ALM, , Talend, SQL Server 2005, 2008 and 2008 R2  Windows , IBM InfoSphere, SSIS , SSRS XML, Excel, Access, Visio."}
{"text": ""}
{"text": "Client:   PRA Internationals, Raleigh, NC\t\t                                                              Jun 2008 to July 2009   "}
{"text": "Role:Data Modeler / Business Data Analyst /Data Architect"}
{"text": "PRA Internationals is dedicated to providing a variety of high quality professional health services to the health communities.As a top five CRO, we have worked on 100+ marketed drugs across several therapeutic areas and conducted the pivotal or supportive trials that led to FDA and/or international regulatory approval of 50+ such drugs."}
{"text": "Project description:"}
{"text": "The purpose of this project was to design an information system for a patient health records in a hospital. Computer-based patient records (CPR\u2019s) give all the information about a person\u2019s health. The project used Health Level (HL7) naming standards in its effort to attain integrity with government records. Development of data model contained data elements such as patient (CPR), primary care physician (GP), Emergency room (ER), test centers for diagnostics and reports, drugs available at store etc. Scope of the project is limited by ignoring the insurance plans and payment modes made by the patient. Provided Logical Data Model (LDM) and Physical Data Modeling (PDM) reviews with Data SMEs. Keep focus on tight integration overlap and Informatica\u2019s newer commitment to MDM with the acquisition of Identity Systems.  the data governor to data quality monitoring against production data in the goldensource to communicate errors in data entry back to the operations team members or to technology for corrective action."}
{"text": "Key Achievements"}
{"text": "Responsible for creating Databases, Tables, Cluster/Non-Cluster Index, Unique/Check Constraints Views, Stored Procedures, Triggers, Rules."}
{"text": "Perform administrative tasks, including creation of database objects such as database, tables, and views, using SQL DCL, DDL, and DML requests."}
{"text": "Used BTEQ script to create a sample tables. Redefine the partitioning of a populated table."}
{"text": "Creating a User-defined Function To Verify a Date. "}
{"text": "Used various Transformations in SSIS Dataflow, Control Flow using for loop Containers, and Fuzzy Lookups. Created several Staging Databases. Used SSIS and T-SQL stored procedures to transfer data from OLTP databases to staging area and finally transfer into data marts and performed action in XML."}
{"text": "Designed and developed complex mappings to extract data from diverse sources including flat files, RDBMS tables, legacy system files."}
{"text": "Environment:  Oracle 10g, OBIEE,Erwin 7.5.2, SQL Server 2005 and 2008, Windows XP, XML, Talend, Excel, Access, Visio."}
{"text": ""}
{"text": "Client:   Circuit City Stores, Inc.  Glen Allen, VA                                                                Feb 2000 to Nov 2008        Role:     Business data analyst / Data modeler"}
{"text": "Creating Logical and Physical Data Model (Erwin 3.0) Reviewed numerous Use Cases, Activity Diagrams, UML Models, and ER Diagrams. Create EDW Strategy/Roadmap to include Master Data Management Planning. Data Modeling Design of a 'Common Entities' LDM to consolidate Master Data from multiple sources and allow for data sharing across the organization. I used Oracle Designer 9i and Rational RequisitePro. Also work on e-commerce to provide unique selection of products."}
{"text": "Key Achievements"}
{"text": "Successfully created and managed a conversion testing effort which included a data quality review, two system test cycles, and user acceptance testing."}
{"text": "Using Erwin to logical and Physical DM in SQL-SERVER."}
{"text": "Set referential integrity roles and history options in Erwin Editor."}
{"text": "Use RDBMSs to implement simple CRUD (Create, Read, Update, and Delete)functionality."}
{"text": "In Erwin Diagram display Logical and Physical relationships."}
{"text": "Set in Erwin Diagram Parent to Child identifying relationships. "}
{"text": "Optimized the performance of queries by modifying the existing index system and rebuilding indexes."}
{"text": "Involved in writing SQL programming for implement Stored Procedures and Functions for different tasks."}
{"text": "Environment:Windows 2000, Oracle 8i,OBIEE, ATG Merchandising UI,Data Stage, MS Access, SQL Server 2005 and 2008, Erwin 3."}
{"text": "\t\t"}
{"text": "Education:"}
{"text": "Branford Hall Career Institute, Connecticut USA"}
{"text": "   Diploma in Computer Network Management (SQL Server, Window Server 2006 /2012 R2, Oracle VM Virtual Box, Switches, Routers, and Security)    Grade with A"}
{"text": ""}
{"text": ""}